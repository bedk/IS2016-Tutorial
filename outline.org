* Introduction (Sam - 15 slides)
  - Proliferation of numerous applications with speech interfaces
  - What kinds of information are available for speech signal -
    speaker, what is spoken, environment
  - What applications can be built to tap into these information
    sources - ASR/LID/Speaker ID technologies
  - This means that when these applications get ported to new domains
    and languages, the speech interfaces also then get used in these
    environments
  - Limit discussion to Speech Recognition
  - What is under the hood for speech recognition technologies?
  - Show how each ASR module relies on transcribed data - GMM based
    technology to current DNN based technology
  - Categorize tutorial topics
    A. New Languages - Building from ASR systems from scratch
    B. New domain - Adaptation of an existing ASR system

* New Languages (Brian)
** Babel Program
   - Goals
   - Languages

** Why KWS?
   - Practical application of ASR systems when WER is still high
   - KWS techniques and metrics

** Language characteristics and how they affect performance
*** Is the language tonal?
    If so, the front end needs to explicitly include some sort of
    pitch feature or provide the same information implicitly via a
    higher resolution spectral input and sufficiently long context
    window.
*** Does the language have a complex, agglutinative morphology?
    If so, OOV rates for test data will be high, which will impact
    performance.  Web text for the LM and vocabulary may help.
*** What is the writing system?
    This will affect the generation of the pronunciation lexicon.
    Possibilities are
    - Ideographic
    - Alphabet
    - Abjad
    - Abugida
    Ideographic languages require a character-to-pronunciation
    lexicon, while in many cases the other writing systems may be
    handled with simple rule-based spelling-to-sound conversion.
*** How much transcribed data is available?
    If there is only a little, can mitigate with
    - multilingual feature front-ends
    - multilingual AMs
    - Data augmentation
    - Semi-supervised training
    - Active Learning?  (bedk - not sure if we want to talk about
      this or not)

** Babel recipe
*** Graphemic models
**** Lexicon
**** Questions for decision tree

*** Flat start

*** Multilingual features
**** Network architectures
**** Impact on system performance

*** Web data
**** Variability across languages
**** Impact on system performance

* New Domains (Bhuvana - 20 slides)
  - Building systems so that they can hold up in novel conditions or
    adapt system
    - Multi-condition training
    - Feature adaptation
    - Model adaptation for GMM - Neural networks
    - LM adaptation

** Recipes (Bhuvana - 15 slides)
   - Aspire example - mismatch AM - multi-condition training
   - Call-center example - mismatch AM - LM

* Summary of current technologies (Bhuvana - 5 slides)

* Research Topics, Challenges, and New Ideas (Florian)

* End-to-End Systems (Florian)

* Virtual Machines and Tools (Florian)

* Conclusions (Florian)
